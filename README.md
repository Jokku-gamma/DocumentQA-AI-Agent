# For more professional and easy understanding README.md generated by AI tools

# Document QA AI Agent

This project implements an AI-powered Document Question Answering (QA) system that can answer questions based on uploaded PDF documents (using Retrieval Augmented Generation - RAG) and also leverage an external tool to search for academic papers on Arxiv. The system features a simple web-based chat interface.

## Features

* **PDF Document Upload:** Upload PDF files, and the system will process them for querying.
* **Document-Specific QA (RAG):** Ask questions about the content of your uploaded PDFs.
* **Arxiv Paper Lookup:** The AI agent can intelligently decide to search for academic papers on Arxiv based on your natural language queries (e.g., "Find recent papers on neural networks").
* **Intelligent Tool Calling:** The backend Large Language Model (LLM) decides whether to use the internal RAG system or the external Arxiv lookup tool based on your query.
* **User-Friendly Web Interface:** A simple HTML/CSS/JavaScript frontend for interaction.

## Technologies Used

### Backend (Python)
* **FastAPI:** Web framework for building the API.
* **OpenAI API:** For Large Language Model (LLM) capabilities, including function/tool calling.
* **ChromaDB:** A vector database for storing document embeddings for RAG.
* **PyMuPDF (fitz):** For extracting text from PDF documents.
* **pytesseract:** Python wrapper for Tesseract OCR, used for image-based text extraction (if PDFs contain images of text).
* **arxiv:** Python wrapper for the Arxiv API.
* **langchain-text-splitters:** For splitting documents into manageable chunks.
* **uvicorn:** ASGI server to run the FastAPI application.
* **python-dotenv:** For managing environment variables (like API keys).

### Frontend (Web)
* **HTML, CSS, JavaScript:** Standard web technologies for the user interface.

## Prerequisites

Before you begin, ensure you have the following installed on your system:

1.  **Python 3.8 or higher:**
    * [Download Python](https://www.python.org/downloads/)
2.  **Node.js & npm (Optional, not strictly required for this frontend setup but good practice for web development):**
    * [Download Node.js](https://nodejs.org/en/download/)
3.  **OpenAI API Key:**
    * You'll need an API key from OpenAI to use their language models.
    * [Get your OpenAI API Key](https://platform.openai.com/account/api-keys)
4.  **Tesseract OCR Engine:**
    * The `pytesseract` Python library is just a wrapper. You need the actual Tesseract OCR software installed on your operating system.
    * **Windows:** Download the installer from [Tesseract at UB Mannheim](https://github.com/UB-Mannheim/tesseract/wiki). **During installation, make sure to select the option to "Add Tesseract to PATH" or manually add the installation directory (e.g., `C:\Program Files\Tesseract-OCR`) to your system's `Path` environment variables. You must restart your terminal/IDE after adding to PATH.**
    * **macOS:** Install via Homebrew: `brew install tesseract`
    * **Linux (Debian/Ubuntu):** `sudo apt update && sudo apt install tesseract-ocr && sudo apt install tesseract-ocr-eng` (for English language pack)

## Setup Instructions

Follow these steps to get your Document QA AI Agent up and running.

### 1. Project Structure

Ensure your project is structured like this:

DOCQA/
├── backend/
│   ├── main.py
│   ├── config.py (or you can use .env directly as shown below)
│   ├── models.py
│   ├── gemini_service.py
│   └── requirements.txt
└── frontend/
├── index.html
├── style.css
└── script.js

### 2. Backend Setup

1.  **Navigate to the `backend` directory:**
    ```bash
    cd your_project_root/backend
    ```
    (Replace `your_project_root` with the actual path to your project)

2.  **Create `requirements.txt`:**
    If you don't have one, create a file named `requirements.txt` in your `backend` directory with the following content:
    ```
    fastapi[all]
    openai
    chromadb
    langchain-text-splitters
    pymupdf
    python-filetype
    Pillow
    pytesseract
    arxiv
    uvicorn
    python-dotenv
    ```

3.  **Create and Activate Virtual Environment:**
    It's highly recommended to use a virtual environment to manage dependencies.
    ```bash
    python -m venv venv
    ```
    * **Activate on Windows (PowerShell):**
        ```powershell
        .\venv\Scripts\Activate.ps1
        ```
    * **Activate on Windows (Command Prompt):**
        ```cmd
        .\venv\Scripts\activate.bat
        ```
    * **Activate on macOS/Linux/Git Bash:**
        ```bash
        source venv/bin/activate
        ```
    Your terminal prompt should now show `(venv)` indicating the environment is active.

4.  **Install Python Dependencies:**
    With your virtual environment activated, install all required packages:
    ```bash
    pip install -r requirements.txt
    ```

5.  **Configure OpenAI API Key:**
    Create a file named `.env` in your `backend` directory and add your OpenAI API key:
    ```
    # backend/.env
    OPENAI_API_KEY="your_openai_api_key_here"
    ```
    **Replace `"your_openai_api_key_here"` with your actual API key.**

### 3. Running the Application

1.  **Start the Backend Server:**
    Ensure your virtual environment is active and you are in the `backend` directory.
    ```bash
    uvicorn main:app --reload
    ```
    The backend server will start, typically accessible at `http://127.0.0.1:8000`. Keep this terminal window open.

2.  **Run the Frontend:**
    Navigate to your `frontend` directory in your file explorer.
    Open the `index.html` file in your preferred web browser.
    * You can usually just double-click the `index.html` file.
    * Alternatively, open your browser and type `file:///path/to/your_project_root/frontend/index.html` (replace with your actual path).

    The frontend will load, and its JavaScript will attempt to connect to the backend. You should see the backend status change from "Disconnected" to "Connected" if successful.

## Usage

1.  **Upload Documents:** Use the file upload button to select and upload PDF documents. Once uploaded, you'll see them listed.
2.  **Ask Questions:** Type your questions into the input field and press Enter or click "Send".
    * **Document QA:** Ask questions related to the content of your uploaded PDFs (e.g., "What is the abstract of 532.pdf?" or "Summarize the introduction of the e-bike safety paper.").
    * **Arxiv Search:** Ask for general research papers, and the AI will use the Arxiv tool (e.g., "Find recent papers on neural networks" or "Are there any new articles on quantum computing?").
3.  **Observe Responses:** The bot's responses will appear in the chat interface. If the backend is configured to send structured data for Arxiv results, your frontend should render them in a more visually appealing card-like format.

## Important Notes & Troubleshooting

* **CORS:** If you encounter Cross-Origin Resource Sharing (CORS) errors, ensure your FastAPI backend's `CORS_ORIGINS` (or `allow_origins`) are correctly configured to include the origin from which your frontend is served (e.g., `http://127.0.0.1:8000` if you're serving it via a local dev server, or `null` if opening `file://`). The current setup uses `allow_origins=["*"]` for simplicity during development, but restrict this in production.
* **Tesseract PATH:** The most common issue is Tesseract not being in your system's PATH. Always verify by opening a *new* terminal/command prompt and typing `tesseract --version`. If it's not found, recheck your installation and PATH settings.
* **OpenAI API Key:** Double-check that your `OPENAI_API_KEY` is correctly set in your `.env` file within the `backend` directory.
* **Frontend Rendering:** For a truly "beautiful" output of structured data (like Arxiv papers), ensure your `script.js` parses the `result.type` from the backend and constructs appropriate HTML elements as discussed in our previous conversations. For general text responses, consider using a markdown rendering library in your frontend to parse markdown from the LLM.
* **Error Messages:** Pay attention to error messages in both your backend terminal and your browser's developer console (F12) for debugging.

---